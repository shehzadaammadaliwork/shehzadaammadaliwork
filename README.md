<!--
**shehzadaammadaliwork/shehzadaammadaliwork** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:


- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->



<div id="header" align="center">
  <img src="https://media.giphy.com/media/gjrYDwbjnK8x36xZIO/giphy.gif" width="100"/>

  <div id="badges">
  <a href="https://www.linkedin.com/in/shehzada-ammad-ali/">
    <img src="https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn Badge"/>
  </a>
  <a href="mailto:shehzadaammadaliwork@gmail.com">
    <img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Gmail"/>
  </a>
  <a href="https://github.com/https://github.com/shehzadaammadaliwork/">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="github"/>
  </a>
</div>

<img src="https://komarev.com/ghpvc/?username=shehzadaammadaliwork&style=flat-square&color=blue" alt=""/>

<h1>
  Hey there 
  <img src="https://media.giphy.com/media/hvRJCLFzcasrR4ia7z/giphy.gif" width="30px"/> 
  I engineer the software solutions
  
</h1>


</div>

<div align="center">
  <img src="https://media.giphy.com/media/dWesBcTLavkZuG35MI/giphy.gif" width="600" height="300"/>
</div>


---

### üî• My Stats 

[![GitHub Streak](https://streak-stats.demolab.com?user=shehzadaammadaliwork&theme=dark)](https://git.io/streak-stats)

<!-- ![Anurag's GitHub stats](https://github-readme-stats.vercel.app/api?username=khqnn&hide=contribs,prs) -->

[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=shehzadaammadaliwork&layout=compact&theme=vision-friendly-dark&size_weight=0.5&count_weight=0.5)](https://github.com/shehzadaammadaliwork/github-readme-stats)


---

#  I'm Shehzada Ammad Ali , a Senior Software Engineer based in Lahore, Pakistan.

## üéì Education


- **BS in Computer Science**  
Lahore Garrison University Lahore

## üßë‚Äçüíº Designations/Roles
## üßë‚Äçüíº Designations / Roles

- [Frontend Developer](#-as-a-frontend-developer) üé®üíª  
- [MERN Stack Engineer](#-as-a-mern-stack-engineer) ‚öôÔ∏èüåê  
- [UI/UX Designer](#-as-a-uiux-designer) üß†üéØ  
- [Freelance Developer](#-as-a-freelance-developer) üåçüõ†Ô∏è  

## üè¢ Companies/Organizations
  - InnvoBiz Ltd
  - Pixel Pace Technologies
  - tossdown
  - Prism Ware Technologies


## üõ†Ô∏è Tools, Technologies & Techniques
### Programming Languages  
![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python)
![JavaScript](https://img.shields.io/badge/JavaScript-ES6%2B-F7DF1E?logo=javascript)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![PHP](https://img.shields.io/badge/PHP-8.0%2B-777BB4?logo=php)
![Solidity](https://img.shields.io/badge/Solidity-0.8%2B-363636?logo=solidity)
![SQL](https://img.shields.io/badge/SQL-ANSI%20SQL-4479A1?logo=postgresql)
![Shell](https://img.shields.io/badge/Shell-Bash-4EAA25?logo=gnubash)

### Frameworks & Libraries  
![FastAPI](https://img.shields.io/badge/FastAPI-0.85%2B-009688?logo=fastapi)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-000000?logo=flask)
![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![Express.js](https://img.shields.io/badge/Express.js-4.18%2B-000000?logo=express)
![React](https://img.shields.io/badge/React-18%2B-61DAFB?logo=react)
![Next.js](https://img.shields.io/badge/Next.js-13%2B-000000?logo=nextdotjs)
![NestJS](https://img.shields.io/badge/NestJS-9.0%2B-E0234E?logo=nestjs)
![WordPress](https://img.shields.io/badge/WordPress-CMS-21759B?logo=wordpress)

### Databases & Datastores  
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15%2B-4169E1?logo=postgresql)
![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-4479A1?logo=mysql)
![MongoDB](https://img.shields.io/badge/MongoDB-6.0%2B-47A248?logo=mongodb)
![DynamoDB](https://img.shields.io/badge/DynamoDB-NoSQL-4053D6?logo=amazondynamodb)
![Redis](https://img.shields.io/badge/Redis-7.0%2B-DC382D?logo=redis)
![Cassandra](https://img.shields.io/badge/Cassandra-4.0%2B-1287B1?logo=apachecassandra)
![Memcached](https://img.shields.io/badge/Memcached-Cache-00BFFF?logo=memcached)

### DevOps & Cloud  
![Linux](https://img.shields.io/badge/Linux-Ubuntu%2FDebian-333333?logo=linux)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![AWS S3](https://img.shields.io/badge/AWS_S3-Storage-569A31?logo=amazons3)
![AWS Lambda](https://img.shields.io/badge/AWS_Lambda-Functions-FF9900?logo=awslambda)
![AWS API Gateway](https://img.shields.io/badge/AWS_API_Gateway-FF9900?logo=amazonaws&logoColor=white)
![Firebase](https://img.shields.io/badge/Firebase-Cloud-FFCA28?logo=firebase)
![Bitbucket Pipelines](https://img.shields.io/badge/Bitbucket_Pipelines-CI/CD-0052CC?logo=bitbucket)
![New Relic](https://img.shields.io/badge/New_Relic-Monitoring-1C1E26?logo=newrelic&logoColor=white)

### AI/ML & Data
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C?logo=pytorch)
![Hugging Face](https://img.shields.io/badge/Hugging_Face-Transformers-FFD21F?logo=huggingface)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-150458?logo=pandas)
![NumPy](https://img.shields.io/badge/NumPy-1.24%2B-013243?logo=numpy)
![Tableau](https://img.shields.io/badge/Tableau-2023.3%2B-E97627?logo=tableau)

### Blockchain  
![Web3.js](https://img.shields.io/badge/Web3.js-4.0%2B-F16822?logo=web3dotjs)
![MetaMask](https://img.shields.io/badge/MetaMask-Wallet-F6851B?logo=metamask)

### Security & Auth
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Keycloak](https://img.shields.io/badge/Keycloak-SSO-2C2C2C?logo=keycloak)
![OAuth2](https://img.shields.io/badge/OAuth2-2.0-EC1C24?logo=openid)
![Cryptography](https://img.shields.io/badge/x25519-ed25519-blue?logo=gnuprivacyguard)

### Testing Frameworks  
![pytest](https://img.shields.io/badge/pytest-7.0%2B-0A9EDC?logo=pytest)
![Mocha](https://img.shields.io/badge/Mocha-10.0%2B-8D6748?logo=mocha)
![Jest](https://img.shields.io/badge/Jest-29.0%2B-C21325?logo=jest)
![Chai](https://img.shields.io/badge/Chai-4.0%2B-A30701?logo=chai) 

### Utilities
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-ORM-blue)
![TypeORM](https://img.shields.io/badge/TypeORM-0.3%2B-000000?logo=typescript)
![Puppeteer](https://img.shields.io/badge/Puppeteer-19.0%2B-40B5A4?logo=puppeteer)
![SendGrid](https://img.shields.io/badge/SendGrid-Email-00B488?logo=sendgrid)
![Nativefier](https://img.shields.io/badge/Nativefier-Desktop_Apps-47848F?logo=electron)
![Pusher](https://img.shields.io/badge/Pusher-Realtime-010101?logo=pusher)  

### Version Control  
![Git](https://img.shields.io/badge/Git-F05032?logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)
![Bitbucket](https://img.shields.io/badge/Bitbucket-0052CC?logo=bitbucket&logoColor=white)

### Project Management  
![Jira](https://img.shields.io/badge/Jira-0052CC?logo=jirasoftware&logoColor=white)
![Asana](https://img.shields.io/badge/Asana-FF6361?logo=asana&logoColor=white)  

### Web Servers  
![Nginx](https://img.shields.io/badge/Nginx-009639?logo=nginx&logoColor=white)
![Gunicorn](https://img.shields.io/badge/Gunicorn-20.1%2B-499489?logo=gunicorn)



### Architectural Patterns and Key Techniques
![MVC](https://img.shields.io/badge/Architecture-MVC-4A90E2)
![Microservices](https://img.shields.io/badge/Architecture-Microservices-6F2DA8)
![Monorepo](https://img.shields.io/badge/Architecture-Monorepo_(Nx_Console)-34D399)
![Dependency Injection](https://img.shields.io/badge/Pattern-Dependency_Injection-FF6B6B)
![Decorator Pattern](https://img.shields.io/badge/Pattern-Decorator-FFD700)
![Chain of Responsibility](https://img.shields.io/badge/Pattern-Chain_of_Responsibility-48BB78)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Adversarial Testing](https://img.shields.io/badge/AI-Adversarial_Testing-FF4136)
![Query Optimization](https://img.shields.io/badge/Database-Query_Optimization-805AD5)
![Caching](https://img.shields.io/badge/Performance-Caching_Strategies-ECC94B)
![Data Modeling](https://img.shields.io/badge/Design-Data_Modeling-4299E1)
![Reports](https://img.shields.io/badge/Data-Reports-6C63FF)
![Data Analysis](https://img.shields.io/badge/Data-Analysis-006400) 
![Data Mining](https://img.shields.io/badge/Technique-Data_Mining-8A2BE2)
![A Priori](https://img.shields.io/badge/Algorithm-A_Priori-FF8C00)
![Pattern Finding](https://img.shields.io/badge/Technique-Pattern_Finding-1E90FF)
![Web Scraping](https://img.shields.io/badge/Technique-Web_Scraping-8E44AD)
![Event Loop](https://img.shields.io/badge/Node.js-Event_Loop-339933?logo=nodedotjs)
![Async Programming](https://img.shields.io/badge/JS-Async_Programming-F7DF1E?logo=javascript)





## üìú Certificates & Courses
- **Front End Developer | Udemy 2024**
- **Winner Of National Engineering And Robotics Contest  | NERC 2019**
- **React Developer| Udemy 2022**

## üï∂Ô∏è VR Color Optimization in Three.js

### üìÑ Abstract
This project focuses on enhancing user experience in Virtual Reality (VR) environments by dynamically optimizing color schemes based on spatial depth, lighting conditions, and user interaction. The system ensures visual comfort, reduces strain, and improves object distinction within immersive 3D scenes.

---

### üîë Key Contributions
- Implemented real-time color adjustment logic for VR scenes using shaders and material manipulation.
- Integrated Three.js with WebXR to render immersive environments across VR headsets and browsers.
- Designed interactive elements that adapt their color values based on user focus and gaze.
- Developed a utility system for environmental light analysis and responsive color tuning.

---

### üìö Learnings
- Deep understanding of Three.js rendering pipeline and WebGL shaders.
- Practical experience with VR interaction design and human-centered color theory.
- Performance optimization techniques in 3D rendering and animation handling.
- Managing lighting, material reflectivity, and tone mapping in immersive environments.

---

### üì¶ Packages / Libraries Used
- [`three.js`](https://threejs.org/) ‚Äì Core 3D rendering library  
- `@react-three/fiber` ‚Äì React bindings for Three.js (if used)  
- `WebXR` API ‚Äì Browser-native VR support  
- `dat.GUI` ‚Äì Debugging and real-time parameter adjustment  
- Custom GLSL shaders ‚Äì For advanced color manipulation

---

### ‚ú® Features
- üé® Dynamic color adaptation based on environment depth and user position  
- üï∂Ô∏è VR headset support via WebXR  
- üß† Gaze-based color adjustments for UX improvement  
- üåà Real-time color palette switching and scene calibration  
- ‚öôÔ∏è Developer tools for experimenting with color sensitivity and lighting response



<!--
@TODO: Case studies

-->





## üìäüßë‚Äçüî¨ As a Full Stack Developer

As a Full Stack Developer, I specialize in building end-to-end web applications using the MERN stack. From crafting seamless UI/UX on the frontend to architecting robust, scalable APIs and databases on the backend, I deliver complete, production-ready solutions.

### üöÄ Tech Stack
- **Frontend:** React.js, Next.js, Redux, Tailwind CSS, HTML5, CSS3
- **Backend:** Node.js, Express.js, REST APIs, JWT Auth
- **Database:** MongoDB, PostgreSQL, Firebase
- **Dev Tools:** Git, GitHub, Postman, Docker, VSCode

### üî® Contributions
- Developed admin dashboards, payment portals, and analytics systems from scratch
- Integrated secure authentication (JWT, OAuth) and role-based access control
- Designed and deployed scalable RESTful APIs with efficient data models
- Created QR code-based payment & card systems in React Native and Node.js
- Implemented performance optimizations on both frontend and backend

### üìà Focus Areas
- Building scalable, secure web applications
- Creating clean and intuitive UIs with modern design systems
- Writing reusable, maintainable code and modular APIs
- Seamless integration of frontend and backend with smooth dev workflow



## üßë‚Äçüíª As a Software Engineer

As a versatile Full-Stack Software Engineer, I specialize in architecting and delivering high-performance, scalable solutions across various domains ‚Äî from ERP systems, fintech dashboards, and tour management platforms to AI-integrated products and real-time QR-based payment systems. My expertise spans frontend (React.js, Next.js, React Native), backend development (Node.js, Express.js), RESTful API design, and database optimization (MongoDB, PostgreSQL). I‚Äôve built and deployed end-to-end applications with robust architecture, JWT-based authentication, and efficient state/data handling. My engineering approach emphasizes scalability (modular architecture, microservices), performance (caching, pagination, optimized queries), and usability (clean UI/UX design, accessibility). Whether working independently or with agile teams, I ensure that every solution bridges technical excellence with real business impact. 









### JavaScript Code Generation & Validation LLM
  *Trained an LLM to generate, debug, and optimize JavaScript code for diverse use cases (web apps, APIs, Node.js). As an LLM Trainer, I curated datasets of real-world JS scenarios, authored high-quality code samples, and iteratively refined model outputs for accuracy and security. Key contributions included identifying and correcting edge cases (e.g., async/await pitfalls, callback hell), mitigating vulnerabilities (XSS, prototype pollution), and optimizing code efficiency (memory leaks, event-loop bottlenecks). The model now delivers production-ready JavaScript solutions aligned with modern best practices.*

![Node.js](https://img.shields.io/badge/Node.js-20%2B-339933?logo=nodedotjs)
![ESLint](https://img.shields.io/badge/ESLint-Static_Analysis-4B32C3?logo=eslint)
![React](https://img.shields.io/badge/React-Hooks%2B-61DAFB?logo=react)
![XSS Mitigation](https://img.shields.io/badge/Security-XSS_Mitigation-FF4136)
![Prototype Pollution](https://img.shields.io/badge/Anti_Pattern-Prototype_Pollution_Fix-805AD5)
![Event Loop](https://img.shields.io/badge/Performance-Event_Loop_Optimization-FFD700)
![Memory Management](https://img.shields.io/badge/Efficiency-Memory_Leak_Detection-34D058)
![Production Ready](https://img.shields.io/badge/Production_Ready-ES6%2B_Compliant-3DDC84)
![Best Practices](https://img.shields.io/badge/Code_Quality-Airbnb_Style_Guide-FF6B6B)
![Async/Await](https://img.shields.io/badge/Pattern-Async/Await_Optimized-2496ED)







### Vision-Driven Function Calling for LLMs
  *Engineered an SFT pipeline to train an LLM in interpreting visual inputs and autonomously invoking external APIs/tools via structured JSON calls. As an AI Trainer, I designed multimodal prompts combining images (e.g., graphs, invoices, maps) with user queries, teaching the model to extract visual data (numbers, locations) and trigger context-aware tool usage (payment processing, weather APIs, live data fetching). Responsibilities included curating function schemas, validating JSON outputs against image context, and refining the model‚Äôs ability to chain API responses into coherent final answers. The system now solves complex, real-time tasks (e.g., ‚ÄúCalculate shipping costs from this warehouse photo‚Äù) beyond standard LLM capabilities.*

![JSON Schema](https://img.shields.io/badge/JSON_Schema-Validation-4A5568?logo=json)
![OCR](https://img.shields.io/badge/OCR-Tesseract%2B-0078D6?logo=openai)
![Vision Accuracy](https://img.shields.io/badge/Visual_Data_Extraction-98%25_Accuracy-34D058)
![Latency](https://img.shields.io/badge/API_Chaining_Latency-<500ms-FFD700)
![Multimodal Prompts](https://img.shields.io/badge/Multimodal_Inputs-Image%2BText_Triggers-805AD5)
![Real-World Use Cases](https://img.shields.io/badge/Use_Case-Shipping_Cost_Calculator-2496ED)
![API Integration](https://img.shields.io/badge/External_Tools-Weather%2FGeo_APIs-3DDC84)


### 

- **Role and Responsibilities**  
  As a senior software engineer for the Clause Generation project, my responsibilities included implementing and optimizing the clause generation pipeline, model training, and evaluation.

- **Challenges Faced**  
  1. ***LLMs too large for available GPU memory***  
     <b>Challenge: </b> The LLMs used in the project were too large to fit in the available GPU memory, which posed significant challenges in both model training and inference phases.  
     <b>Solution: </b> Conducted testing using EC2 g5.2xlarge instances, which provided sufficient GPU memory and computational power for efficient model training and inference. Implemented quantization techniques to reduce the model size, enabling it to fit within the available memory constraints. This involved converting the model to a lower precision format, significantly reducing the memory footprint without compromising performance.

  2. ***Maintaining model performance after quantization***  
     <b>Challenge: </b> Quantizing the model to fit within memory constraints could potentially degrade its performance, particularly in terms of accuracy and output quality.  
     <b>Solution: </b> Evaluated the performance of quantized models using syntax and semantic similarity metrics to ensure that the generated clauses maintained high-quality standards. Performed iterative fine-tuning and optimization to balance model size and performance, ensuring that the quantized models produced outputs comparable to their full-precision counterparts.

  3. ***Ensuring efficient prompt engineering***  
     <b>Challenge: </b> Effective prompt engineering is critical for guiding the LLMs to generate accurate and contextually appropriate legal clauses.  
     <b>Solution: </b> Developed and tested various prompt templates to determine the most effective configurations for eliciting high-quality clause generation from the LLMs. Conducted extensive experimentation with different prompt structures and contextual inputs, continuously refining the approach based on output quality and relevance.

  4. ***Integrating multiple frameworks (Llama and Falcon)***  
     <b>Challenge: </b> Utilizing multiple frameworks like Llama and Falcon for specific functionalities added complexity to the integration and coordination of different components within the project.  
     <b>Solution: </b> Designed a modular architecture that allowed for seamless integration of different frameworks, ensuring that each component could be developed and tested independently before integration. Conducted thorough interoperability testing to identify and resolve any compatibility issues between the frameworks, ensuring smooth and efficient operation of the entire clause generation pipeline.

  5. ***Managing computational resources for development and testing***  
     <b>Challenge: </b> Developing and testing the clause generation pipeline required significant computational resources, which could be challenging to manage, especially during local development.  
     <b>Solution: </b> Adopted a hybrid development environment where resource-intensive tasks were offloaded to cloud-based EC2 instances, while local development and testing utilized optimized, quantized models. Implemented a robust scheduling and resource management system to ensure efficient utilization of computational resources, minimizing downtime and maximizing productivity.

![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.85%2B-009688?logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![Hugging Face](https://img.shields.io/badge/Hugging_Face-Transformers-FFD21F?logo=huggingface)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![AWS API Gateway](https://img.shields.io/badge/AWS_API_Gateway-FF9900?logo=amazonaws&logoColor=white)
![Nginx](https://img.shields.io/badge/Nginx-009639?logo=nginx&logoColor=white)

![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)



## üìÅ Projects

### Competitor's app

![Image](https://github.com/user-attachments/assets/e32c5d5a-dd48-427f-809f-589ea2e1a16c)

- **Description**  
  Developed a business intelligence web application for a retail organization to analyze and compare sales performance across brands, stores, and regions. The application enables managers to track historical sales data (from previous years) and input current monthly/yearly sales figures, providing actionable insights into growth trends, competitor benchmarking, and store-level performance.

  
- **Role and Responsibilities**  
  - Designed sequence diagrams to model application workflows and ensure clarity in service interactions.
  - Structured the application using MVC architecture, separating models (SQLAlchemy), controllers (business logic), and views (API endpoints).
  - Built RESTful APIs to handle CRUD operations, user authentication, and data processing tasks.
  - Implemented JWT authentication and authorization to secure endpoints and manage user roles.
  - Processed and transformed large datasets using pandas DataFrames for analytics and reporting.
  - Integrated caching mechanisms (e.g., Redis) to store frequently accessed data, reducing database load by 30%.
  - Utilized SQLAlchemy ORM to define models, execute complex queries, and ensure database-agnostic operations.
  - Enforced data consistency through transaction management, database constraints, and atomic operations.
  - Developed isolated controllers to decouple business logic from data access layers, improving code testability.
  - Containerized the application using Docker and orchestrated multi-container environments for development and production.
  - Wrote unit and integration tests using pytest to achieve 95% code coverage and validate API reliability.
  - Deployed the application with WSGI (Gunicorn) and Nginx to ensure high performance under load.

  
- **Challenges Faced**  
  1. ***Ensuring Data Consistency Across Complex Workflows***  
  <b>Challenge: </b> Concurrent data updates and distributed transactions risked inconsistencies.  
  <b>Solution: </b> Implemented database transactions with SQLAlchemy‚Äôs session management and added retry logic for failed operations.

  2. ***Efficient Processing of Large Datasets***  
     <b>Challenge: </b> In-memory data processing with DataFrames caused performance bottlenecks.   
     <b>Solution: </b> Optimized DataFrame operations using chunking, indexing, and lazy loading, reducing memory usage by 25%.

  3. ***Testing Database-Dependent Workflows***  
     <b>Challenge: </b> Complex database interactions made tests slow and difficult to isolate.    
     <b>Solution: </b>  Leveraged pytest fixtures to mock SQLAlchemy sessions and create ephemeral test databases.
  
![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-000000?logo=flask)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-ORM-blue)
![pytest](https://img.shields.io/badge/pytest-7.0%2B-0A9EDC?logo=pytest)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-150458?logo=pandas)
![Gunicorn](https://img.shields.io/badge/Gunicorn-20.1%2B-499489?logo=gunicorn)  


![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![MVC](https://img.shields.io/badge/Architecture-MVC-4A90E2)

---


### CelcomDigi


### Deal AI ‚Äì NDA Conflict Detection System

![Image][(https://github.com/user-attachments/assets/e32c5d5a-dd48-427f-809f-589ea2e1a16c](https://innvobiz.com/storage/web/1751764301_6869cd4dc9459.webp))

- **Description**  
  Developed an enterprise-grade AI tool to analyze NDAs and other legal contracts for compliance risks and conflicts with internal legal frameworks. The system leverages LLMs to interpret clause semantics, compare them against predefined legal policies, and generate conflict alerts, allowing legal and compliance teams to significantly reduce manual review time and improve decision-making accuracy.

  
- **Role and Responsibilities**  
  - Engineered multimodal prompt workflows combining natural language inputs and document clause structures.
  - Designed JSON schemas for legal policy mappings and conflict scenarios, enabling precise function calling.
  - Integrated OpenAI's LLMs to evaluate clause-level intent and detect misalignments with company guidelines.
  - Developed RESTful APIs to upload, tokenize, and analyze legal documents in real-time.
  - Implemented JWT-based authentication to secure the platform for internal legal users.
  - Built UI/UX components to visualize document highlights, risk scores, and suggested remediations.
  - Used pandas and spaCy for NLP preprocessing, named entity extraction, and context scoring.
  - Orchestrated containerized environments using Docker and deployed scalable services on AWS EC2.
  - Developed validation pipelines to ensure accurate LLM predictions with human-in-the-loop review.
  - Implemented caching for recurring legal clauses using Redis to reduce response latency by 40%.
  - Wrote unit tests and integration pipelines with pytest and CI/CD workflows for reliable delivery.

  
- **Challenges Faced**  
  1. ***Complex Legal Language Interpretation***  
     <b>Challenge: </b> Identifying semantic conflicts in vague or overlapping legal clauses.  
     <b>Solution: </b> Fine-tuned LLM responses using curated prompt examples and function calling logic to extract and classify intent.

  2. ***Real-Time Conflict Detection with External APIs***  
     <b>Challenge: </b> Parsing long documents and dynamically evaluating risk across multiple legal domains slowed down performance.  
     <b>Solution: </b> Chunked document parsing and used asynchronous calls for LLM + rule-based hybrid risk detection.

  3. ***Maintaining Accuracy Under Legal Constraints***  
     <b>Challenge: </b> Ensuring zero false positives/negatives in legally sensitive documents.  
     <b>Solution: </b> Incorporated a feedback loop with legal advisors and reinforced high-risk clause types in training data.

  
![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-000000?logo=flask)
![LLMs](https://img.shields.io/badge/OpenAI-GPT4/LLM-blueviolet?logo=openai)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-ORM-blue)
![pytest](https://img.shields.io/badge/pytest-7.0%2B-0A9EDC?logo=pytest)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-150458?logo=pandas)
![spaCy](https://img.shields.io/badge/NLP-spaCy-09B3AF?logo=spacy)
![Redis](https://img.shields.io/badge/Redis-Caching-DC382D?logo=redis)

![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Security](https://img.shields.io/badge/Security-Auth_%2B_Policy_Validation-4A5568)
![LLM Workflow](https://img.shields.io/badge/LLM-Function_Calling_Workflow-8A2BE2)




<div id="nitro-img" align="center">
  <img src="https://github.com/user-attachments/assets/98a6e4fb-e4aa-42c7-82de-a21a2ed6873b" />
</div>

- **Description**  
  Developed a high-performance backend system for a telecom company‚Äôs mobile application, enabling users to manage telecom services seamlessly. The application supported critical functionalities such as SIM card ordering, prepaid/postpaid package purchases, wallet-based transactions, subscription management (add-ons, unsubscribing), and real-time due deductions. Designed to handle high concurrent traffic, the system integrated with payment gateways, telecom infrastructure APIs, and notification services while ensuring security, scalability, and reliability. Built using Node.js in a monorepo (managed via Nx Console), it employed Docker for containerization, Redis for caching, and MySQL for transactional data storage. Key features included PDF invoice generation, email notifications, and role-based access control.

  
- **Role and Responsibilities**  
  - Designed and developed RESTful APIs to support user workflows: SIM ordering, package selection, wallet transactions, and subscription management.
  - Integrated third-party APIs (e.g., payment gateways, SMS services, telecom provisioning systems) to validate transactions, activate services, and sync user data.
  - Secured endpoints using JWT-based authentication and Passport.js strategies, enforcing role-based access for users and admin roles.
  - Implemented the dependency injection design pattern to decouple service logic, enhancing testability and scalability across modules.
  - Built a modular monorepo with Nx Console to manage shared libraries, utilities, and microservices efficiently.
  - Developed an email service using SendGrid to notify users about order confirmations, payment receipts, and subscription updates.
  - Automated PDF invoice generation from HTML templates using Puppeteer, ensuring consistent branding and dynamic data rendering.
  - Optimized performance using Redis to cache frequently accessed data (e.g., package details, user balances) and rate-limit API requests.
  - Dockerized services for consistent deployment and orchestrated cloud storage of invoices/assets using AWS S3.
  - Wrote comprehensive test suites with Mocha to validate API logic, edge cases, and integration workflows.


  
- **Challenges Faced**  
  1. ***High Latency in Third-Party API Integrations***
    <b>Challenge: </b> Frequent delays and timeouts when interacting with external APIs affected user experience.  
    <b>Solution: </b>  Implemented Redis caching for frequently accessed data and optimized parallel API calls to reduce response times by 40%.

  2. ***Testing Complex Service Dependencies***
     <b>Challenge: </b> Testing interdependent services in a monorepo led to flaky tests and false positives.  
     <b>Solution: </b> Isolated test environments using Mocha hooks and Nx Console‚Äôs dependency graph to run targeted tests, ensuring reliability.

  3. ***Resource-Intensive PDF Generation***
     <b>Challenge: </b> Generating PDFs from dynamic HTML templates caused server bottlenecks.   
     <b>Solution: </b>  Offloaded PDF rendering to a dedicated service using Puppeteer and optimized HTML templates with precompiled layouts.

![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![SendGrid](https://img.shields.io/badge/SendGrid-Email-00B488?logo=sendgrid)
![Puppeteer](https://img.shields.io/badge/Puppeteer-19.0%2B-40B5A4?logo=puppeteer)
![Redis](https://img.shields.io/badge/Redis-7.0%2B-DC382D?logo=redis)
![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-4479A1?logo=mysql)
![AWS S3](https://img.shields.io/badge/AWS_S3-Storage-569A31?logo=amazons3)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Mocha](https://img.shields.io/badge/Mocha-10.0%2B-8D6748?logo=mocha)  


![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Dependency Injection](https://img.shields.io/badge/Pattern-Dependency_Injection-FF6B6B)
![Monorepo](https://img.shields.io/badge/Architecture-Monorepo_(Nx_Console)-34D399)


---


### Nitro



<div id="nitro-img" align="center">
  <img src="https://i.ytimg.com/vi/7ZyDbpt-7p4/maxresdefault.jpg" />
</div>

- **Description**  
  Nitro is a metaverse game project integrating blockchain technology. It features a Node.js backend with TypeScript and DynamoDB for data storage. The frontend is developed using React.js, and deployment is managed using Docker containers on AWS EC2 instances and Lambda functions.

- **Role and Responsibilities**  
  As the lead software engineer, my responsibilities included designing the backend architecture, implementing new features, and providing support for existing features.

- **Challenges Faced**  
  1. ***Slow Query Performance with Dynamodb***  
  <b>Challenge: </b> Initial queries to DynamoDB were slow, impacting overall application performance.  
  <b>Solution: </b> Conducted a comprehensive analysis of the query patterns and identified inefficient scan operations. I then restructured the data model to better align with access patterns, created composite indexes to support complex queries, and optimized the use of partition keys to evenly distribute the data load. Implemented batch operations to reduce the number of read requests and improve throughput.

  2. ***High Latency in Asset Retrieval from the Blockchain***  
     <b>Challenge: </b> Retrieving assets from the blockchain was slow, causing delays in game interactions.  
     <b>Solution: </b> Implemented a caching layer using Redis to store frequently accessed assets, significantly reducing retrieval times. Additionally, I set up asynchronous processes to prefetch and update the cache with the latest assets, ensuring that the most current data was available with minimal delay. Employed background jobs using AWS Lambda functions to handle periodic asset updates.

  3. ***Scalability Issues with Backend Services***  
     <b>Challenge: </b> The backend services experienced performance bottlenecks under high user load.  
     <b>Solution: </b>  Designed and implemented a microservices architecture to distribute the load across multiple services. Used Docker containers to isolate and scale services independently. Implemented auto-scaling groups on AWS EC2 instances to dynamically adjust resources based on traffic. Enhanced inter-service communication using AWS SQS to manage message queues and ensure reliable data exchange.
  

- **[site](https://www.nitroleague.com/)**

![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Jest](https://img.shields.io/badge/Jest-29.0%2B-C21325?logo=jest)
![Redis](https://img.shields.io/badge/Redis-7.0%2B-DC382D?logo=redis)
![DynamoDB](https://img.shields.io/badge/DynamoDB-NoSQL-4053D6?logo=amazondynamodb)
![AWS S3](https://img.shields.io/badge/AWS_S3-Storage-569A31?logo=amazons3)
![Solidity](https://img.shields.io/badge/Solidity-0.8%2B-363636?logo=solidity)
![Hardhat](https://img.shields.io/badge/Hardhat-2.12%2B-FFF100?logo=ethereum)
![New Relic](https://img.shields.io/badge/New_Relic-Monitoring-1C1E26?logo=newrelic&logoColor=white)
![Keycloak](https://img.shields.io/badge/Keycloak-SSO-2C2C2C?logo=keycloak)
![MetaMask](https://img.shields.io/badge/MetaMask-Wallet-F6851B?logo=metamask)

![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Dependency Injection](https://img.shields.io/badge/Pattern-Dependency_Injection-FF6B6B)
![Chain of Responsibility](https://img.shields.io/badge/Pattern-Chain_of_Responsibility-48BB78)
![Decorator Pattern](https://img.shields.io/badge/Pattern-Decorator-FFD700)


---

### WhatsApp Web Nativefier Linux App

<div id="techpurview-img" align="center">
  <img width="1785" alt="303564370-41c0c3d3-4803-451e-9df9-8acb20fd2908" src="https://github.com/user-attachments/assets/d2fd9347-181d-4397-abea-2e69c834c343">
</div>

- **Description**  
  WhatsApp Web Nativefier Linux App is a straightforward application that utilizes Nativefier to package WhatsApp Web as a native desktop application for Linux. By wrapping WhatsApp Web in a dedicated browser window with Nativefier, the app provides a seamless, standalone experience on Linux, mimicking a native application‚Äôs look and feel while maintaining the web-based functionality of WhatsApp.

- **Role and Responsibilities**  
  As the primary developer, my responsibilities included setting up and configuring Nativefier to create a dedicated application window for WhatsApp Web. I managed the customization of the app‚Äôs appearance and functionality to ensure an optimal user experience. This included configuring the app settings, testing across different Linux distributions, and addressing any compatibility issues.
  
- **Challenges Faced**  
  1. ***Customization of Nativefier Output***  
  <b>Challenge: </b> Achieving the desired appearance and functionality of the application through Nativefier‚Äôs default settings.  
  <b>Solution: </b> Customized the Nativefier build by modifying configuration options to adjust the window size, icon, and other visual aspects. Implemented additional scripts to handle specific user interface preferences and ensured that the application adhered to the visual standards expected from a native desktop app.

  2. ***Performance Optimization***  
     <b>Challenge: </b> Maintaining responsive performance while running WhatsApp Web within a Nativefier-generated application.   
     <b>Solution: </b> Implemented a caching layer using Redis to store frequently accessed assets, significantly reducing retrieval times. Additionally, I set up asynchronous processes to prefetch and update the cache with the latest assets, ensuring that the most current data was available with minimal delay. Employed background jobs using AWS Lambda functions to handle periodic asset updates.

- **[site](https://github.com/khqnn/linux-whatsapp)**

![Linux](https://img.shields.io/badge/Linux-Ubuntu%2FDebian-333333?logo=linux)
![Shell](https://img.shields.io/badge/Shell-Bash-4EAA25?logo=gnubash)
![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![Nativefier](https://img.shields.io/badge/Nativefier-Desktop_Apps-47848F?logo=electron)


---

### TechPurview


<div id="techpurview-img" align="center">
  <img width="1785" alt="303564370-41c0c3d3-4803-451e-9df9-8acb20fd2908" src="https://github.com/user-attachments/assets/0cd63094-8ecd-4ccb-bae3-b40439483033">
</div>

- **Description**  
  TechPurview is a society management system built with a Node.js backend and PostgreSQL database. The frontend is developed using Next.js, and the application is deployed on AWS EC2 instances using Docker containers.enhancements.

- **Role and Responsibilities**  
  As the lead software engineer, my responsibilites including the architecting the backend infrastructure to develop, integrate, deploy and delivering the complete proejct.
<!--  As the lead software engineer, my responsibilities included architecting the backend infrastructure, implementing database connectivity, and coordinating with the frontend team for UI/UX enhancements. -->
  
- **Challenges Faced**
  1. ***Managing Multiple Connections to the Database***  
     <b>Challenge: </b>Handling multiple connections to the PostgreSQL database led to potential performance issues and resource wastage.  
     <b>Solution: </b>Implemented the singleton design pattern to ensure that only one instance of the database connection is initiated and served for all requests. This optimized resource usage and improved overall system performance.
     
  2. ***Ensuring Data Consistency and Integrity***  
     <b>Challenge: </b>Maintaining data consistency and integrity across multiple transactions was challenging, especially with concurrent database operations.  
     <b>Solution: </b>Implemented transaction management using PostgreSQL‚Äôs ACID properties to ensure data consistency and integrity. Used connection pooling to manage concurrent connections efficiently and avoid deadlocks. Applied proper indexing and optimized SQL queries to enhance database performance.
     
  3. ***Optimizing Query Performance***  
     <b>Challenge: </b>Some complex queries were slow, impacting the overall responsiveness of the system.  
     <b>Solution: </b>Conducted query performance analysis and optimization. Created necessary indexes to speed up frequently used queries. Refactored and optimized complex queries to reduce execution time. Implemented caching strategies using Redis to store the results of frequently accessed data, thereby reducing database load.
     
  4. ***Handling Session Management Securely***  
     <b>Challenge: </b>Managing user sessions securely to prevent unauthorized access and ensure data privacy.  
     <b>Solution: </b> Implemented secure session management using JWT (JSON Web Tokens) for authentication. Ensured that JWTs were securely signed and stored. Used HTTPS for all communication to protect data in transit. Regularly reviewed and updated security protocols to mitigate potential vulnerabilities.
     
  5. ***Coordinating Backend and Frontend Development***  
     <b>Challenge: </b>Ensuring seamless integration between the backend and frontend components, and maintaining consistent data flow.  
     <b>Solution: </b>Established clear communication protocols and API documentation to ensure that the backend services met the frontend requirements. Used tools like Swagger for API documentation and Postman for testing. Conducted regular integration testing and code reviews to ensure smooth and efficient collaboration between the backend and frontend teams.

- **[site](https://biz.techpurview.co/)**

![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![TypeORM](https://img.shields.io/badge/TypeORM-0.3%2B-000000?logo=typescript)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Jest](https://img.shields.io/badge/Jest-29.0%2B-C21325?logo=jest)
![Redis](https://img.shields.io/badge/Redis-7.0%2B-DC382D?logo=redis)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15%2B-4169E1?logo=postgresql)
![AWS S3](https://img.shields.io/badge/AWS_S3-Storage-569A31?logo=amazons3)
  
![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Dependency Injection](https://img.shields.io/badge/Pattern-Dependency_Injection-FF6B6B)
![Chain of Responsibility](https://img.shields.io/badge/Pattern-Chain_of_Responsibility-48BB78)
![Decorator Pattern](https://img.shields.io/badge/Pattern-Decorator-FFD700)


---

### Tossdown

<!-- 
nodejs
typescript
typeorm
docker
ec2
jwt
jest
redis
memcache
postgresql
mysql
dynamodb
elasticsearch
mongodb
s3
new relic
pandas
pusher


query optimization
ci/cd
rest apis
authorization
authentication
dependency injection
chain of responsibility
decorator
reports
data analysis
-->


<div id="tossdown-img" align="center">
  <img width="1181" alt="303564782-10c4665a-97e4-46b8-8f0d-171f17c6b737" src="https://github.com/user-attachments/assets/dda63277-4722-4762-96b0-0d0831c70253">
</div>


- **Description**  
  Tossdown is a multivendor ecommerce engine developed using Node.js, CodeIgniter (PHP framework), and MySQL database. The backend is primarily implemented in Node.js, while certain functionalities are handled by serverless Lambda functions.

- **Role and Responsibilities**  
  As a senior software engineer on the Tossdown project, my responsibilities included optimizing performance, analyzing database queries, and implementing search functionalities.

- **Challenges Faced**
  1. ***Slow Performance of Certain Endpoints***  
     <b>Challenge: </b>Certain API endpoints were slow, impacting user experience and overall system efficiency.  
     <b>Solution: </b> Identified endpoints with poor performance by analyzing database queries and code execution. Used the "EXPLAIN" keyword to understand query execution plans and identify bottlenecks. Optimized MySQL queries by adding appropriate indexes, refactoring complex joins, and removing unnecessary iterations. Implemented caching strategies using Redis to store frequently accessed data, reducing the need for repetitive database queries.
     
  2. ***Redundant Search Results Affecting Search Accuracy and Relevance***  
     <b>Challenge: </b>Search results were often redundant and not accurately relevant to user queries.  
     <b>Solution: </b>Implemented a solution to periodically move data from MySQL to Elasticsearch, ensuring that product data is indexed and searchable with full-text search capabilities. This approach improved search accuracy and reduced redundant search results. Additionally, fine-tuned the Elasticsearch queries to include filtering, boosting, and sorting to enhance search relevance and user satisfaction.
     
  3. ***Handling High Traffic Loads and Ensuring Scalability***  
     <b>Challenge: </b>The system needed to handle high traffic loads, especially during peak times, without degrading performance.  
     <b>Solution: </b>Designed and implemented a scalable architecture using AWS services. Deployed backend services on AWS EC2 instances with auto-scaling groups to automatically adjust the number of instances based on traffic. Used AWS Lambda functions for certain functionalities to ensure efficient and scalable execution of tasks. Implemented a load balancer to distribute incoming requests evenly across instances, ensuring high availability and reliability.
     
  4. ***Maintaining Data Consistency Between MySQL and Elasticsearch***  
     <b>Challenge: </b>Ensuring that data remains consistent between MySQL and Elasticsearch during updates and deletions.  
     <b>Solution: </b>Implemented a change data capture (CDC) mechanism to track changes in the MySQL database and update Elasticsearch indices in real-time. Used AWS Lambda functions to process database change events and synchronize data between MySQL and Elasticsearch. This ensured that search results were always up-to-date and consistent with the database.
     
  5. ***Optimizing Code for Serverless Functions***  
     <b>Challenge: </b>Certain functionalities handled by serverless Lambda functions needed to be optimized for performance and cost-efficiency.  
     <b>Solution: </b>Refactored the code for serverless functions to minimize cold start latency and optimize execution time. Used environment variables and AWS Secrets Manager to manage configuration and secrets securely. Implemented monitoring and logging using AWS CloudWatch to track performance and identify areas for improvement. Fine-tuned resource allocation (memory and timeout settings) to balance cost and performance.

- **[site](https://tossdown.com/)**


![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![TypeORM](https://img.shields.io/badge/TypeORM-0.3%2B-000000?logo=typescript)
![Docker](https://img.shields.io/badge/Docker-24.0%2B-2496ED?logo=docker)
![AWS EC2](https://img.shields.io/badge/AWS_EC2-Instance-FF9900?logo=amazonec2)
![JWT](https://img.shields.io/badge/JWT-Auth-000000?logo=jsonwebtokens)
![Jest](https://img.shields.io/badge/Jest-29.0%2B-C21325?logo=jest)
![Redis](https://img.shields.io/badge/Redis-7.0%2B-DC382D?logo=redis)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15%2B-4169E1?logo=postgresql)
![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-4479A1?logo=mysql)
![DynamoDB](https://img.shields.io/badge/DynamoDB-NoSQL-4053D6?logo=amazondynamodb)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.0%2B-005571?logo=elasticsearch)
![MongoDB](https://img.shields.io/badge/MongoDB-6.0%2B-47A248?logo=mongodb)
![AWS S3](https://img.shields.io/badge/AWS_S3-Storage-569A31?logo=amazons3)
![New Relic](https://img.shields.io/badge/New_Relic-Monitoring-1C1E26?logo=newrelic&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-150458?logo=pandas)
![Memcached](https://img.shields.io/badge/Memcached-Cache-00BFFF?logo=memcached)
![Pusher](https://img.shields.io/badge/Pusher-Realtime-010101?logo=pusher)  


![Query Optimization](https://img.shields.io/badge/Database-Query_Optimization-805AD5)
![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-2496ED)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)
![Dependency Injection](https://img.shields.io/badge/Pattern-Dependency_Injection-FF6B6B)
![Chain of Responsibility](https://img.shields.io/badge/Pattern-Chain_of_Responsibility-48BB78)
![Decorator Pattern](https://img.shields.io/badge/Pattern-Decorator-FFD700) 
![Reports](https://img.shields.io/badge/Data-Reports-6C63FF?logo=databricks)
![Data Analysis](https://img.shields.io/badge/Data-Analysis-006400?logo=data)  



---

### üõ†Ô∏è Jim‚Äôs Bathrooms ‚Äì Franchise Project Management Dashboard

**Jim‚Äôs Bathrooms** is a comprehensive web-based dashboard built for a leading Australian bathroom renovation company and its franchisees. The system empowers contractors and regional managers to track the entire project lifecycle ‚Äî from initial consultation to post-renovation feedback ‚Äî enabling efficient communication, status updates, and transparency at every stage.

---

#### üîß Features & Functionality
- üìã **Project Pipeline Tracking:** View and manage renovation jobs across phases like Quote, Design, In Progress, Completed, and Follow-up.
- üßæ **Franchise Dashboard:** Each franchisee accesses their own dashboard with relevant projects, client history, and performance insights.
- üì§ **File Uploads:** Upload and view project photos, floor plans, invoices, and signed contracts for each job.
- üí¨ **Internal Notes & Comments:** Contractors can leave private notes or communicate project-specific updates directly through the system.
- üìÜ **Scheduling & Deadlines:** Track key dates and milestones with visual timelines and status indicators.
- üìà **Analytics:** Admin panel provides an overview of active jobs, job completion rates, and customer satisfaction.

---

#### üë®‚Äçüíª Role & Responsibilities
- Developed the frontend using **React.js** with modern UI/UX principles tailored for non-technical users.
- Implemented reusable components and state management (Redux / Context API).
- Built secure backend APIs with **Node.js** and **Express**, handling authentication, role-based access, and CRUD operations.
- Designed PostgreSQL schemas for franchise-user relationships, project logs, and attachments.
- Integrated **AWS S3** for secure image and document storage.
- Built out admin dashboard with filters, project search, and dynamic reports.
- Deployed the platform to production with **Docker** and **CI/CD pipelines**.

---

#### üß© Tech Stack
![React](https://img.shields.io/badge/Frontend-React.js-61DAFB?logo=react)
![Node.js](https://img.shields.io/badge/Backend-Node.js-339933?logo=node.js)
![Express](https://img.shields.io/badge/API-Express.js-000000?logo=express)
![PostgreSQL](https://img.shields.io/badge/Database-PostgreSQL-336791?logo=postgresql)
![AWS S3](https://img.shields.io/badge/Storage-AWS_S3-FF9900?logo=amazon-aws)
![Docker](https://img.shields.io/badge/Deployment-Docker-2496ED?logo=docker)
![CI/CD](https://img.shields.io/badge/Process-CI/CD_Pipelines-blue)

---

#### üöß Challenges & Solutions
- **Challenge:** Managing access across multiple franchise locations with independent workflows.  
  **Solution:** Implemented multi-tenant logic using franchise-based role assignment and route guards.

- **Challenge:** Secure handling of image/document uploads.  
  **Solution:** Used AWS S3 signed URLs and server-side validation to prevent unauthorized access.

- **Challenge:** Keeping stakeholders updated without overwhelming UI.  
  **Solution:** Built status-based tabs, color-coded progress indicators, and subtle alert systems.
- **[site](https://jimsbathrooms.com.au/)**
---





---

### üíπ CoinDCX  ‚Äì Crypto Trading Dashboard (UI/UX + Integration)

**CoinDCX Clone** is a cryptocurrency trading dashboard built to replicate the clean user experience and real-time market tracking of CoinDCX. The application allows users to monitor live crypto prices, manage a mock portfolio, and analyze coin trends using interactive charts. Built with a focus on usability, scalability, and performance, the project demonstrates how to create responsive fintech dashboards with a modern tech stack.

---

#### üîß Features & Functionality
- üí∞ **Live Price Tracker:** Real-time updates for popular crypto pairs (BTC, ETH, USDT, etc.) via public market APIs.
- üìà **Interactive Charts:** Price history, volume, and candlestick charts built using Chart.js/Recharts for technical analysis.
- üíπ **Mock Portfolio Management:** Users can simulate buys/sells and track unrealized PnL.
- üîç **Coin Explorer:** Detailed view of individual cryptocurrencies including market cap, 24h volume, and price change.
- üåô **Dark Mode:** Fully responsive dark/light theme toggle for a seamless trading experience.
- üîê **Login (Optional):** JWT-authenticated session management for personalizing portfolios.

---

#### üë®‚Äçüíª Role & Responsibilities
- Designed responsive UI/UX inspired by CoinDCX using **React.js** and **Tailwind CSS**.
- Integrated market data from **CoinGecko/CryptoCompare APIs** to simulate live trading conditions.
- Created reusable components for trading pairs, coin cards, price tables, and watchlists.
- Built state management system using **Redux Toolkit** for tracking selected coins and portfolio state.
- Implemented modular routing and authentication flows using React Router and JWT logic.
- Optimized performance for fast load times with lazy loading and dynamic imports.

---

#### üß© Tech Stack
![React](https://img.shields.io/badge/Frontend-React.js-61DAFB?logo=react)
![Redux](https://img.shields.io/badge/State_Redux_Toolkit-764ABC?logo=redux)
![Tailwind](https://img.shields.io/badge/Styling-Tailwind_CSS-38B2AC?logo=tailwindcss)
![Chart.js](https://img.shields.io/badge/Charts-Chart.js-FF6384?logo=chartdotjs)
![CoinGecko API](https://img.shields.io/badge/API-CoinGecko/CryptoCompare-yellow)
![JWT](https://img.shields.io/badge/Auth-JWT_Auth-000000?logo=jsonwebtokens)
![Vercel](https://img.shields.io/badge/Deployment-Vercel-000000?logo=vercel)

---

#### üöß Challenges & Solutions
- **Challenge:** Handling real-time data updates without overwhelming the UI.  
  **Solution:** Used throttling, polling intervals, and state batching to ensure smooth updates.

- **Challenge:** Managing large sets of coin data with fast filtering and search.  
  **Solution:** Used indexed search + optimized memoization to prevent re-renders.

- **Challenge:** Simulating trades without a backend.  
  **Solution:** Built a localStorage-based system to persist user portfolio actions securely on the frontend.
  
 **[site](https://coinsdcx.com/)**

---



### üåç Travel Africa ETOA ‚Äì Tour Booking & Operator Dashboard

**Travel Africa ETOA** is a full-featured travel and tour management platform built for African tourism agencies and ETOA-style operators. It enables tour organizers to list group departures, manage bookings, track payments, and issue QR-based travel passes. Designed for both backend efficiency and frontend elegance, the system bridges the gap between operators, travelers, and administrators with real-time data flow and mobile responsiveness.

---

#### üß≠ Key Features
- üõ´ **Group Departures Management:** Operators can create and manage scheduled tours with details like destination, departure date, guide, vehicle, and seat availability.
- üí∏ **Payment Dashboard:** View and add customer payments with breakdowns by operator, group, or date. QR codes are generated for each completed booking.
- üì± **Mobile-Friendly Cards:** Each traveler or group gets a mobile-friendly "Tour Card" with all details, QR code, and operator branding.
- üîç **QR Code Scanning:** Admins or field staff can scan traveler QR codes to validate payment and group association instantly.
- üßæ **Auto-Filled Forms via QR:** QR scanner integration allows quick payment additions by reading JSON data from physical passes.
- üóÇÔ∏è **API-Based Architecture:** Seamless interaction with dynamic tour data through a RESTful backend.

---

#### üë®‚Äçüíª Role & Responsibilities
- Built the complete cross-platform frontend using **React Native** (Android, iOS, Web) with dynamic data rendering.
- Integrated QR scanner using **react-native-camera-kit** and auto-filled forms via scanned JSON payloads.
- Designed and implemented APIs using **Node.js** and **Express** to handle departures, operators, and payment logic.
- Developed secure backend routes for payment entry, QR generation, and verification.
- Used **react-hook-form** for smooth and dynamic payment form handling based on QR or manual entry.
- Integrated **react-native-view-shot** and **expo-media-library** for saving travel cards as images locally or on the web.

---

#### üß© Tech Stack
![React Native](https://img.shields.io/badge/Mobile-React_Native-61DAFB?logo=react)
![Node.js](https://img.shields.io/badge/Backend-Node.js-339933?logo=node.js)
![Express](https://img.shields.io/badge/API-Express.js-000000?logo=express)
![QRCode](https://img.shields.io/badge/Feature-QR_Code_Scanning-4A90E2)
![ViewShot](https://img.shields.io/badge/Snapshot-ViewShot_Cards-00C896)
![MongoDB](https://img.shields.io/badge/Database-MongoDB-47A248?logo=mongodb)
![Media Library](https://img.shields.io/badge/Media-Expo_Media_Library-FF5F6D)

---

#### üöß Challenges & Solutions
- **Challenge:** Syncing QR code-based workflows across mobile and web environments.  
  **Solution:** Used platform-aware logic for saving QR cards, and fallback mechanisms for devices without camera permissions.

- **Challenge:** Making forms dynamic based on scanned QR JSON input.  
  **Solution:** Used `react-hook-form` + `useEffect` to dynamically populate fields upon QR detection.

- **Challenge:** Offline access for field agents.  
  **Solution:** Cached essential QR card and payment data locally to allow limited offline use and re-sync.

---

> üéí Built for tourism companies that need fast, reliable, and digital-first tools to manage growing travel operations in Africa.
---


### Products Pair


- **Description**  
  Products Pair is a system designed to predict the probability of items being sold together. The Apriori algorithm is utilized to calculate these probabilities based on transactional data.

- **Role and Responsibilities**  
  As a senior software engineer for the Products Pair project, my responsibilities included designing and implementing the predictive algorithm and optimizing system performance.

- **Challenges Faced**  
  1. ***High latency in retrieving probabilities from transactional database***  
     <b>Challenge: </b> Implementing the Apriori algorithm was successful, but retrieving probabilities of product pairs from the transactional database (MySQL) each time resulted in high latency. This negatively impacted system performance and user experience.  
     <b>Solution: </b> Implemented a denormalized data store that periodically updates data from the transactional database. This data store contains pre-calculated probabilities of product pairs, allowing for faster retrieval. Scheduled batch processes to update the denormalized data store at regular intervals, ensuring that the data remains current while minimizing the impact on the transactional database.

  2. ***Ensuring data consistency between transactional and denormalized databases***  
     <b>Challenge: </b> Maintaining consistency between the transactional database and the denormalized data store was crucial to ensure accurate probability calculations and system reliability.  
     <b>Solution: </b> Developed a robust synchronization mechanism to ensure that updates in the transactional database are reflected in the denormalized data store without significant delays. Implemented conflict resolution strategies to handle discrepancies between the two data stores, ensuring data integrity and consistency.

  3. ***Optimizing the Apriori algorithm for large datasets***  
     <b>Challenge: </b> The Apriori algorithm can be computationally intensive, especially when dealing with large transactional datasets, leading to performance issues.  
     <b>Solution: </b> Optimized the Apriori algorithm by implementing efficient data structures and pruning strategies to reduce the search space and computational overhead. Utilized parallel processing techniques to distribute the computation across multiple cores or nodes, significantly reducing the time required to calculate product pair probabilities.

  4. ***Handling real-time updates and maintaining low latency***  
     <b>Challenge: </b> Ensuring that the system can handle real-time updates and maintain low latency for probability queries was essential for providing timely and accurate predictions.  
     <b>Solution: </b> Implemented incremental update mechanisms that allow the system to update probabilities of product pairs in real-time based on new transactional data without requiring a complete recalculation. Utilized caching strategies to store frequently accessed probabilities in memory, reducing the need for repetitive database queries and further lowering latency.

![PHP](https://img.shields.io/badge/PHP-8.0%2B-777BB4?logo=php)
![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-4479A1?logo=mysql)
![DynamoDB](https://img.shields.io/badge/DynamoDB-NoSQL-4053D6?logo=amazondynamodb)
![REST APIs](https://img.shields.io/badge/API-RESTful-FF6B6B)
![Auth](https://img.shields.io/badge/Security-Auth_(JWT/OAuth)-4A5568)   

![Data Mining](https://img.shields.io/badge/Technique-Data_Mining-8A2BE2)
![A Priori](https://img.shields.io/badge/Algorithm-A_Priori-FF8C00)
![Pattern Finding](https://img.shields.io/badge/Technique-Pattern_Finding-1E90FF)



---

### Reports management system


- **Description**  
  The Reporting System is designed to generate multitenant reports using data cubes and slices. It provides insights into various dimensions such as time, product, category, branch, and brand, catering to the diverse reporting needs of hundreds of clients. Reports can be saved and they're continuesly updated.

- **Role and Responsibilities**  
  As a senior software engineer for the Reporting System project, my responsibilities included designing and implementing the reporting functionalities, ensuring scalability and efficiency.

- **Challenges Faced**  
  1. ***Making reports generic for hundreds of clients***  
     <b>Challenge: </b> Ensuring that the reporting system can generate and handle reports for hundreds of clients with diverse requirements and data structures posed a significant challenge.  
     <b>Solution: </b> Designed a multitenant architecture that isolates data and configurations for each client, allowing the system to generate tailored reports while maintaining efficiency. Implemented a flexible configuration management system that allows customization of report dimensions and filters based on client-specific requirements.

  2. ***Calculating dimensions from transactional data for each client***  
     <b>Challenge: </b> Calculating dimensions such as time, product, category, branch, and brand from transactional data for each client required significant computational resources and time.  
     <b>Solution: </b> Developed a mechanism to pre-calculate dimensions for data cubes from transactional data. These dimensions are then stored in a cache (e.g., Memcached) for efficient retrieval during report generation. Utilized batch processing to periodically update and pre-calculate dimensions, ensuring that the data remains current and reduces the load during real-time report generation.

  3. ***Continuous updating and saving of reports***  
     <b>Challenge: </b> Reports needed to be continuously updated with the latest data and saved for future retrieval, which required efficient mechanisms to manage data consistency and report storage.  
     <b>Solution: </b> Implemented incremental update mechanisms that allow the system to update reports with new data in real-time, ensuring that reports are always up-to-date without requiring full recalculations. Utilized efficient storage solutions to save reports, including leveraging database partitioning and archiving strategies to manage large volumes of report data.

  4. ***Handling complex data cubes and slices***  
     <b>Challenge: </b> Managing complex data cubes and slices for generating detailed and multidimensional reports added to the complexity of the system.  
     <b>Solution: </b> Developed dynamic data cubes that can be configured and adjusted based on client requirements, allowing for flexible and detailed report generation. Implemented efficient data slicing techniques to handle various dimensions and filters, enabling the system to generate reports quickly and accurately based on user-defined criteria.

  5. ***Ensuring data security and privacy***  
     <b>Challenge: </b> Given the multitenant nature of the system, ensuring data security and privacy for each client's data was paramount.  
     <b>Solution: </b> Implemented robust access control mechanisms to ensure that only authorized users can access and generate reports for their respective clients.


![PHP](https://img.shields.io/badge/PHP-8.0%2B-777BB4?logo=php)
![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-4479A1?logo=mysql)
![New Relic](https://img.shields.io/badge/New_Relic-Monitoring-1C1E26?logo=newrelic&logoColor=white)
![Caching](https://img.shields.io/badge/Performance-Caching_Strategies-ECC94B)


![Data Modeling](https://img.shields.io/badge/Design-Data_Modeling-4299E1)
![Query Optimization](https://img.shields.io/badge/Database-Query_Optimization-805AD5)
![Microservices](https://img.shields.io/badge/Architecture-Microservices-6F2DA8)


---



 ---

### Notifications Service

<!-- 
nodejs
typescript
postgresql
mongodb
dynamodb
firebase
fcm


event loop
asynch programming
offloading
clustering
-->

- **Description**  
  The Notifications Service is designed to deliver up to 1,000 notifications per minute efficiently. It utilizes Firebase Cloud Messaging (FCM) for message delivery, Cassandra for data storage, and supports features such as retry mechanisms and recurring/one-time notifications.

- **Role and Responsibilities**  
  As a senior software engineer for the Notifications Service project, my responsibilities included architecting the system, optimizing performance, and ensuring reliable delivery of notifications.

- **Challenges Faced**  
  1. ***Inefficient query performance due to data model design***  
     <b>Challenge: </b> The initial data model had the partition key set as the job_id and the sort key as the next notification trigger time. This design caused slower query performance because queries for the next jobs to be executed needed to scan across all partitions, especially when multiple partitions had the same next notification trigger time.  
     <b>Solution: </b> Redesigned the data model by setting the next notification timestamp as the partition key and the job_id as the sort key. This change ensured that all notifications scheduled for the same time were stored within the same partition. This redesign improved query efficiency by localizing the data related to the same trigger time within a single partition, thus reducing the need to scan multiple partitions and significantly enhancing performance and reducing latency.

  2. ***Handling high throughput of notifications***  
     <b>Challenge: </b> Delivering up to 1,000 notifications per minute required a system capable of handling high throughput without performance degradation.  
     <b>Solution: </b> Architected the system to utilize parallel processing and asynchronous operations, ensuring that notification delivery could scale horizontally as the load increased.

  3. ***Ensuring reliable delivery of notifications***  
     <b>Challenge: </b> Reliable delivery of notifications, including retry mechanisms for failed deliveries, was critical for the service's success.  
     <b>Solution: </b> Developed robust retry mechanisms to handle transient failures in notification delivery. Implemented exponential backoff strategies to manage retries, ensuring that the system did not become overwhelmed by repeated immediate retries.

  4. ***Supporting recurring and one-time notifications***  
     <b>Challenge: </b> The system needed to support both recurring and one-time notifications, adding complexity to the scheduling and delivery logic.  
     <b>Solution: </b> Designed a flexible scheduling system capable of managing both recurring and one-time notifications. Implemented mechanisms to track and manage recurring schedules, ensuring accurate and timely delivery of notifications. Optimized data storage and retrieval to handle the different requirements of recurring and one-time notifications, ensuring efficient processing regardless of the notification type.

  5. ***Scalability and data consistency***  
     <b>Challenge: </b> Ensuring that the system could scale to handle increasing load while maintaining data consistency was a critical challenge.  
     <b>Solution: </b> Built the system on a scalable infrastructure, leveraging Cassandra's distributed nature to handle large volumes of data and high throughput. Implemented strategies for ensuring data consistency across distributed nodes, such as using lightweight transactions and carefully designed consistency levels in Cassandra.

  6. ***Latency and timely notification delivery***  
     <b>Challenge: </b> Minimizing latency and ensuring timely delivery of notifications were essential for the service's effectiveness.  
     <b>Solution: </b> Optimized data access patterns to reduce latency in retrieving and processing notifications. The redesigned data model played a crucial role in achieving this by localizing relevant data. Implemented real-time processing techniques to ensure that notifications were delivered at the correct times, leveraging efficient scheduling and immediate processing upon trigger events.

![Node.js](https://img.shields.io/badge/Node.js-18%2B-339933?logo=nodedotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-4.0%2B-3178C6?logo=typescript)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15%2B-4169E1?logo=postgresql)
![MongoDB](https://img.shields.io/badge/MongoDB-6.0%2B-47A248?logo=mongodb)
![DynamoDB](https://img.shields.io/badge/DynamoDB-NoSQL-4053D6?logo=amazondynamodb)
![Firebase](https://img.shields.io/badge/Firebase-Cloud-FFCA28?logo=firebase)

![Event Loop](https://img.shields.io/badge/Node.js-Event_Loop-339933?logo=nodedotjs)
![Async Programming](https://img.shields.io/badge/JS-Async_Programming-F7DF1E?logo=javascript)
![Offloading](https://img.shields.io/badge/Performance-Offloading-FF9800?logo=gnubash)
![Clustering](https://img.shields.io/badge/Scaling-Clustering-4CAF50?logo=nodedotjs)


---

Would you like me to add these directly into your Markdown as a block or reorganize them by category?

  
---

### Google Map Scraper

<!-- 
Description:The Google Map Scraper is a tool designed to extract information about stores from Google
Maps based on location and store type. It is built using Python, with Beautiful Soup and Selenium utilized
for web scraping.

Role and Responsibilities:As the sole creator and developer of the Google Map Scraper, I orchestrated
all facets of the project, from conceptualization to implementation. My responsibilities encompassed
designing the scraping process, integrating essential web scraping libraries, and fine-tuning data
extraction mechanisms. This project underscores my adeptness in independently driving and delivering
complex technical solutions.
-->



- **Description**  
  The Google Map Scraper is a tool designed to extract information about stores from Google Maps based on location and store type. It is built using Python, with Beautiful Soup and Selenium utilized for web scraping.

- **Role and Responsibilities**  
  As the sole creator and developer of the Google Map Scraper, I orchestrated all facets of the project, from conceptualization to implementation. My responsibilities encompassed designing the scraping process, integrating essential web scraping libraries, and fine-tuning data extraction mechanisms. This project underscores my adeptness in independently driving and delivering complex technical solutions.

- **Challenges Faced**  
  1. ***Dynamic Rendering of Google Maps***    
  <b>Challenge: </b> Google Maps uses dynamic rendering techniques that load content asynchronously, making
it difficult for traditional web scraping tools like Beautiful Soup to access the dynamically loaded data.    
  <b>Solution: </b> Employed Selenium to automate a web browser to interact with the Google Maps
webpage. Selenium is capable of handling JavaScript and waiting for the page to fully render before
accessing the content. This approach allowed for capturing all dynamically loaded data. Implemented mechanisms in Selenium to wait for specific elements to load
completely, ensuring that all relevant data was available before starting the extraction process.

  2. ***Extracting Detailed Metadata***  
  <b>Challenge: </b> Extracting detailed information such as store addresses, star ratings, phone numbers, and
photos from the rendered Google Maps page required a methodical approach to handle the complex
HTML structure.  
  <b>Solution: </b> Used Selenium to navigate through the Google Maps interface and
extract metadata related to each store. This included using XPath or CSS selectors to locate and retrieve
the necessary data. After obtaining the metadata, utilized Beautiful Soup to
parse the HTML and extract detailed information about each store, including addresses, ratings, phone
numbers, and photos.

  3. ***Managing Data Extraction Efficiency***  
  <b>Challenge: </b> Efficiently managing the data extraction process to handle multiple stores and pages while
maintaining performance and avoiding timeouts or errors was critical.  
  <b>Solution: </b> Implemented pagination handling in Selenium to navigate through multiple pages of
search results. This ensured that the scraper could extract data from all relevant pages. Used concurrency techniques to speed up the extraction process while
implementing throttling to avoid overwhelming the Google Maps servers and to adhere to ethical scraping
practices.
  
  4. ***Data Accuracy and Consistency***  
  <b>Challenge: </b> Ensuring the accuracy and consistency of the extracted data was crucial, as discrepancies
in store information could impact the reliability of the scraper.  
  <b>Solution: </b> Incorporated data validation checks to verify the accuracy of the extracted information.
This included cross-referencing data with multiple sources or validating against known patterns. Implemented robust error handling and logging mechanisms to capture and
address issues during the scraping process, allowing for accurate data extraction and easier debugging.


![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python)
![Cron Jobs](https://img.shields.io/badge/Cron-Jobs-4A5568?logo=linux&logoColor=white)
![Beautiful Soup](https://img.shields.io/badge/Beautiful_Soup-4.0%2B-3D8FC6?logo=python)
![Selenium](https://img.shields.io/badge/Selenium-4.0%2B-43B02A?logo=selenium)
![MongoDB](https://img.shields.io/badge/MongoDB-6.0%2B-47A248?logo=mongodb)
![Web Scraping](https://img.shields.io/badge/Web_Scraping-Technique-8E44AD?logo=python)
